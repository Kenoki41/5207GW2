---
title: "Group Assignment 2"
author: 'Group 2'
date: "2021/2/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, messages = FALSE)

library (tidyverse)

```


## Data Preparetion

  Data cleaning strategy we used in the lab9

### Downloading and analysing spatial data for elections

\vspace{6mm}

```{r function to download booth data, eval=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/
                  HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), 
           skip = 1)
  
}

```

```{r function to download booth data2, include=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), skip = 1)
  
}

```
\vspace{6mm}

Write out code that downloads and binds the polling place results for each state: 

\vspace{6mm}

```{r load and code 2019 booth data}

booth.results.2019 <- bind_rows(dl.booth.data('NSW'),
                                dl.booth.data('VIC'),
                                dl.booth.data('QLD'),
                                dl.booth.data('WA'),
                                dl.booth.data('SA'),
                                dl.booth.data('TAS'),
                                dl.booth.data('ACT'),
                                dl.booth.data('NT'))

```

\vspace{6mm}

In its raw form this needs some work, though. For instance, there are a lot of small parties who only contested a handful of seats in the election. You can see this for yourself with the syntax: 

\vspace{6mm}

```{r check party coding, eval=FALSE}

table(booth.results.2019$PartyNm)

```

\vspace{6mm}

Therefore we recode the variable `PartyNm`, saving this as `party`: 

\vspace{6mm}

```{r recode party}

booth.results.2019 <- booth.results.2019 %>% 
  mutate(party = dplyr::recode(PartyNm,
                               "Liberal" = 'Coalition',
                               "The Greens" = 'Greens',
                               "Labor" = 'Labor',
                               "Informal" = 'Informal',
                               "Pauline Hanson's One Nation" = 'One Nation',
                               "The Nationals"  = 'Coalition',
                               "The Greens (VIC)" = 'Greens',                    
                               "Australian Labor Party"  = 'Labor',
                               "Liberal National Party of Queensland" = 'Coalition',
                               "The Greens (WA)" = 'Greens',
                               "National Party" = 'Coalition',
                               "Australian Labor Party (Northern Territory) Branch"  = 
                                 'Labor',
                               "Country Liberals (NT)" = 'Coalition',
         .default = 'Other')) %>%
  filter(party != 'Informal')
  
```

\vspace{6mm}

Roll up party votes at each polling place and clean up some of the polls with missing data using `mutate_at`

\vspace{6mm}

```{r calculate proportions for each polling place, message=FALSE, warning=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
group_by(PollingPlaceID, party) %>%
  dplyr::summarise(n = sum(OrdinaryVotes)) %>%
  spread(party, n) %>%
  mutate_at(vars(-PollingPlaceID), 
                   .funs = list(missing = ~ ifelse(is.na(.), 'Yes', 'No'))) %>% 
  mutate_at(vars(-PollingPlaceID), ~ifelse(is.na(.), 0, .))


```

\vspace{6mm}

`gather` to organise the data: 

\vspace{6mm}

```{r other stuff}

  
booth.results.2019 <- booth.results.2019 %>% 
    gather(party, n, 
           Coalition, Greens, Labor, `One Nation`, Other) %>% 
    dplyr::select(PollingPlaceID, party, n) %>% 
    merge(booth.results.2019 %>% 
            gather(party, missing, 
                   Coalition_missing, Greens_missing, 
                   Labor_missing, `One Nation_missing`,
                   Other_missing) %>%
            mutate(party = gsub('_missing', '', party)) %>% 
            dplyr::select(PollingPlaceID, party, missing)) %>% 
  group_by(PollingPlaceID) %>%
  mutate(prop = n / sum(n))

```

\vspace{6mm}

Calculated the proportion of votes at each polling place received by each party saved as `prop`. 

Merging booth information from the AEC on to data frame, and then removing rows with missing data. 

\vspace{6mm}

```{r booth information, eval=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```

```{r booth information2, include=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```


\vspace{6mm}


### Building on data

\vspace{6mm}


```{r read and merge datapacks, eval=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))


```


```{r read and merge datapacks2, include=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))

```

\vspace{6mm}

## Finilizing data cleaning


```{r check data}

variable <- c('Median_age_persons','Median_rent_weekly','Median_tot_prsnl_inc_weekly')

library(psych)

describe(booth.results.2019[variable])

ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_age_persons), binwidth = 2)

ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_rent_weekly), binwidth = 30)

ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_tot_prsnl_inc_weekly), binwidth = 50)



```

### Analysis of part i
  According to the data and graph given above, ```


## Regression model

  Use scale function to standardlized the data and fit regression model with possion distribution.

```{r fit the first linear model to county, warning=FALSE, message=FALSE, cache=FALSE}

library(tidyverse)
booth.results.2019.Coalition <- booth.results.2019 %>%
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Coalition")

booth.results.2019.Greens <- booth.results.2019 %>%
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Greens")

booth.results.2019.Labor <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Labor")

booth.results.2019.OneNation <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "One Nation")

booth.results.2019.Other <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Other")


library(arm)
booth.model.coliation <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Coalition)

booth.model.greens <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Greens)

booth.model.labor <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Labor)

booth.model.onenation <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.OneNation)

booth.model.other <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Other)

display(booth.model.coliation)
display(booth.model.greens)
display(booth.model.labor)
display(booth.model.onenation)
display(booth.model.other)


```


```{r read shp file and merge with existing data}
library(sf)

au.shape.1 <- st_read("Data/Australia/Au shapefiles/POA_2016_AUST.shp")

# Data for Coalition
Coalition.independent.table <- booth.results.2019 %>%
  filter(party == "Coalition") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Average_num_psns_per_bedroom)

## Remove repeated data
Coalition.independent.table <- dplyr::distinct(Coalition.independent.table)

## Merge data by postcode
Coalition.independent.table <- merge(au.shape.1,
  Coalition.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Greens
Greens.independent.table <- booth.results.2019 %>%
  filter(party == "Greens") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Average_num_psns_per_bedroom)

## Remove repeated data
Greens.independent.table <- dplyr::distinct(Greens.independent.table)

## Merge data by postcode
Greens.independent.table <- merge(au.shape.1,
  Greens.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for One Nation
OneNation.independent.table <- booth.results.2019 %>%
  filter(party == "One Nation") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Average_num_psns_per_bedroom)

## Remove repeated data
OneNation.independent.table <- dplyr::distinct(OneNation.independent.table)

## Merge data by postcode
OneNation.independent.table <- merge(au.shape.1,
  OneNation.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Labor
Labor.independent.table <- booth.results.2019 %>%
  filter(party == "Labor") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Average_num_psns_per_bedroom)

## Remove repeated data
Labor.independent.table <- dplyr::distinct(Labor.independent.table)

## Merge data by postcode
Labor.independent.table <- merge(au.shape.1,
  Labor.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Other
Other.independent.table <- booth.results.2019 %>%
  filter(party == "Other") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Average_num_psns_per_bedroom)

## Remove repeated data
Other.independent.table <- dplyr::distinct(Other.independent.table)

## Merge data by postcode
Other.independent.table <- merge(au.shape.1,
  Other.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################


```



```{r plot the map}
library(mapdeck)

# Map the Median age in every postcode area of each party

key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'

mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Coalition.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)

```

```{r}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Greens.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```

```{r}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = OneNation.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```

```{r}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Labor.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```

```{r}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Other.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```




### Key findings
  According to our research: