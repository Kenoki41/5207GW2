---
title: "Group Assignment 2"
author: 'Group 2'
date: "2021/2/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, messages = FALSE)

library (tidyverse)

```


# Introduction and Theory of the Our Assignment

In this assignment, the 3 factors we use are:
  1. median_age_persons
  2. median_rent_weekly
  3. median_tot_prsnl_inc_weekly
  
There's the reason:
  The median is a very meaningful data in population data, and the median reflects the middle level of the data. It divides the data into two parts, one is below the intermediate level and the other is above the intermediate level. 
  
  Here we choose the median age. This is the mainstay of the social population. Those below the median age are young people who have voting rights, and those above the median age are elderly people. Considering that every age group may have a biased attitude towards the program of a certain political party, the median age here is a meaningful data.
  
  Like the median age, the median weekly rent and total personal income are also meaningful data. Rent and income can analyze the disposable income of people in each region, and people with different incomes will have different attitudes to the programs of different political parties. For example, if a party supports tax increases for high-income groups and tax cuts for low-income groups, people with low disposable incomes will maintain a higher support rate for the party. At the same time, because of the high housing prices and incomes in a certain area, there are many high-income groups in this area. Based on such data, we can study the potential relationship between a certain income group and the support rate of a certain party.
  
  
## Assignment Structure

In the first part:
  We have explained the reasons for the selection of the three factors. Next we will use the method on the lab to clean up the data. 
  
  After this we will use the describe() function to observe the mean and standard deviation of the three factors. And use the ggplot function to view the distribution of the data, which gives us a full understanding of the data we want to operate.
  
In the second part:
  The data will be classified according to political parties, and five tables are generated. After that, the glm() function and the Poisson distribution are used to study the relationship between the independent variable and the dependent variable (support rate).
  
  Generate a map based on the variables we selected. For example, the age distribution of people who support the Labor Party, this map is used as the independent variable map. The dependent variable map will be the distribution of the Labor Party’s approval ratings.
  
  Finally, we will draw our conclusions based on the generated map.


# Part I

## Data Preparetion

  Data cleaning strategy we used in the lab9

### Downloading and analysing spatial data for elections

\vspace{6mm}

```{r function to download booth data, eval=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/
                  HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), 
           skip = 1)
  
}

```

```{r function to download booth data2, include=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), skip = 1)
  
}

```
\vspace{6mm}

Write out code that downloads and binds the polling place results for each state: 

\vspace{6mm}

```{r load and code 2019 booth data}

booth.results.2019 <- bind_rows(dl.booth.data('NSW'),
                                dl.booth.data('VIC'),
                                dl.booth.data('QLD'),
                                dl.booth.data('WA'),
                                dl.booth.data('SA'),
                                dl.booth.data('TAS'),
                                dl.booth.data('ACT'),
                                dl.booth.data('NT'))

```

\vspace{6mm}

In its raw form this needs some work, though. For instance, there are a lot of small parties who only contested a handful of seats in the election. You can see this for yourself with the syntax: 

\vspace{6mm}

```{r check party coding, eval=FALSE}

table(booth.results.2019$PartyNm)

```

\vspace{6mm}

Therefore we recode the variable `PartyNm`, saving this as `party`: 

\vspace{6mm}

```{r recode party}

booth.results.2019 <- booth.results.2019 %>% 
  mutate(party = dplyr::recode(PartyNm,
                               "Liberal" = 'Coalition',
                               "The Greens" = 'Greens',
                               "Labor" = 'Labor',
                               "Informal" = 'Informal',
                               "Pauline Hanson's One Nation" = 'One Nation',
                               "The Nationals"  = 'Coalition',
                               "The Greens (VIC)" = 'Greens',                    
                               "Australian Labor Party"  = 'Labor',
                               "Liberal National Party of Queensland" = 'Coalition',
                               "The Greens (WA)" = 'Greens',
                               "National Party" = 'Coalition',
                               "Australian Labor Party (Northern Territory) Branch"  = 
                                 'Labor',
                               "Country Liberals (NT)" = 'Coalition',
         .default = 'Other')) %>%
  filter(party != 'Informal')
  
```

\vspace{6mm}

Roll up party votes at each polling place and clean up some of the polls with missing data using `mutate_at`

\vspace{6mm}

```{r calculate proportions for each polling place, message=FALSE, warning=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
group_by(PollingPlaceID, party) %>%
  dplyr::summarise(n = sum(OrdinaryVotes)) %>%
  spread(party, n) %>%
  mutate_at(vars(-PollingPlaceID), 
                   .funs = list(missing = ~ ifelse(is.na(.), 'Yes', 'No'))) %>% 
  mutate_at(vars(-PollingPlaceID), ~ifelse(is.na(.), 0, .))


```

\vspace{6mm}

`gather` to organise the data: 

\vspace{6mm}

```{r other stuff}

  
booth.results.2019 <- booth.results.2019 %>% 
    gather(party, n, 
           Coalition, Greens, Labor, `One Nation`, Other) %>% 
    dplyr::select(PollingPlaceID, party, n) %>% 
    merge(booth.results.2019 %>% 
            gather(party, missing, 
                   Coalition_missing, Greens_missing, 
                   Labor_missing, `One Nation_missing`,
                   Other_missing) %>%
            mutate(party = gsub('_missing', '', party)) %>% 
            dplyr::select(PollingPlaceID, party, missing)) %>% 
  group_by(PollingPlaceID) %>%
  mutate(prop = n / sum(n))

```

\vspace{6mm}

Calculated the proportion of votes at each polling place received by each party saved as `prop`. 

Merging booth information from the AEC on to data frame, and then removing rows with missing data. 

\vspace{6mm}

```{r booth information, eval=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```

```{r booth information2, include=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```


\vspace{6mm}


### Building on data

\vspace{6mm}


```{r read and merge datapacks, eval=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))


```


```{r read and merge datapacks2, include=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))

```

\vspace{6mm}

## Finilizing data cleaning and descriptive analysis


```{r overview the varaibles we selected and plot distribution graph}

variable <- c('Median_age_persons','Median_rent_weekly','Median_tot_prsnl_inc_weekly')

library(psych)

describe(booth.results.2019[variable])

library(ggplot2)
ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_age_persons), binwidth = 2)

ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_rent_weekly), binwidth = 30)

ggplot(data = booth.results.2019) +
  geom_histogram(mapping = aes(x = Median_tot_prsnl_inc_weekly), binwidth = 50)



```

### Analysis of part I
  According to the data and graph given above, the median age of the voters has a mean of 39.61 and a standard deviation of 6.07 the data of median age is little dispersed,min is 18.00 and max is 67.00. the distribution shows a right skew (skewness +0.48) and is slightly flatter than the normal distribution (kurtosis 0.33)
The mean of voters weekly rent is 325.39 and a standard deviation of 120.13 the weekly rent is dispersed,min is 0 and max is 830. the distribution shows a right skew (skewness +0.53) and is slightly steeper than the normal distribution (kurtosis 1.18)
The mean of voters weekly personal income is 671.82 and a standard deviation of 178.50 the personal income is large dispersed,min is 185 and max is 2772. the distribution shows a right skew (skewness +1.66) and is steeper than the normal distribution (kurtosis 5.82)
From the graph1, we can see that the age pf most voters are between 35 to 40 and about 34 is the most. From the graph2, we can see that most voter are rent between 250 to 375 and nearly 375 is the most. Form the graph3, we can see that most voters personal income is between 500 to 750 and nearly 650 is the most.

# Part II 

## Regression model

  In order to eliminate data differences and improve model accuracy, we decided to use the scale() function to centralize and standardize the data.
  After that, the data supporting each party will be selected.Using the glm() function to build a generalized linear regression model for the data of each party. Then use the Poisson distribution to explain the relationship between the independent variable and the dependent variable.

```{r fit the first linear model to county, warning=FALSE, message=FALSE, cache=FALSE}

library(tidyverse)
booth.results.2019.Coalition <- booth.results.2019 %>%
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Coalition")

booth.results.2019.Greens <- booth.results.2019 %>%
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Greens")

booth.results.2019.Labor <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Labor")

booth.results.2019.OneNation <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "One Nation")

booth.results.2019.Other <- booth.results.2019 %>% 
  mutate(z.age = scale(Median_age_persons)) %>%
  mutate(z.rent = scale(Median_rent_weekly)) %>% 
  mutate(z.income = scale(Median_tot_prsnl_inc_weekly)) %>% 
  filter(party == "Other")


library(arm)
booth.model.coliation <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Coalition)

booth.model.greens <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Greens)

booth.model.labor <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Labor)

booth.model.onenation <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.OneNation)

booth.model.other <- glm(prop ~ z.age + z.rent 
                     + z.income,
                     family=poisson(link = log),
                     data=booth.results.2019.Other)

display(booth.model.coliation)
display(booth.model.greens)
display(booth.model.labor)
display(booth.model.onenation)
display(booth.model.other)


```

## Analysis of the glm

The fitting poisson model examines the coffecient of the independent(the median age, weekly rent, weekly personal income of voters)and dependent variable(probability of election).In the Poisson regression, the dependent variable is modeled in the logarithmic form of the conditional mean ln(λ). The poisson model is (prop ~ z.age + z.rent + z.income).

  For the coalition party, the intercept is -0.88, the regression parameter for z.age is 0.13, indicating that holding the other predictor variables constant, a one-year increase in age will result in a corresponding increase in the log mean of the number of election probability by 0.13.The the regression parameter for z.rent is -0.04, a fee of rent increase will result in a corresponding decrease in the log mean of the number of election probability by 0.04.The regression parameter for z.income is 0.07,  increase in personal income will result in a corresponding increase in the log mean of the number of election probability by 0.07.

  For the greens party, the intercept is -2.32, the regression parameter for z.age is -0.06, indicating that holding the other predictor variables constant, a one-year increase in age will result in a corresponding decrease in the log mean of the number of election probability by 0.06.The the regression parameter for z.rent is 0.18, a fee of rent increase will result in a corresponding increase in the log mean of the number of election probability by 0.18.The regression parameter for z.income is 0.10,  increase in personal income will result in a corresponding increase in the log mean of the number of election probability by 0.10.

  For the Labor party, the intercept is -1.16, the regression parameter for z.age is -0.17, indicating that holding the other predictor variables constant, a one-year increase in age will result in a corresponding decrease in the log mean of the number of election probability by 0.17.The regression parameter for z.rent is 0.08, a fee of rent increase will result in a corresponding increase in the log mean of the number of election probability by 0.08.The regression parameter for z.income is -0.12, increase in personal income will result in a corresponding decrease in the log mean of the number of election probability by 0.12.
  
  For the OneNation party, the intercept is -3.51, the regression parameter for z.age is -0.19, indicating that holding the other predictor variables constant, a one-year increase in age will result in a corresponding decrease in the log mean of the number of election probability by 0.19.The regression parameter for z.rent is -0.50, a fee of rent increase will result in a corresponding decrease in the log mean of the number of election probability by 0.50.The regression parameter for z.income is -0.05,  increase in personal income will result in a corresponding decrease in the log mean of the number of election probability by 0.05.
  
  For the other party, the intercept is -2.08, the regression parameter for z.age is 0.09, indicating that holding the other predictor variables constant, a one-year increase in age will result in a corresponding increase in the log mean of the number of election probability by 0.09.The the regression parameter for z.rent is -0.16, a fee of rent increase will result in a corresponding decrease in the log mean of the number of election probability by 0.16.The regression parameter for z.income is 0.02, increase in personal income will result in a corresponding increase in the log mean of the number of election probability by 0.02.
  
  
  
## Data Cleaning and Opearting
  The purpose of the code in this section is to select the appropriate data (zip code and three independent variables) and merge.
  
  We have some special findings when operating on dependent variables.(See below)

  Mention: The values of independent variables in the same postal code are the same, so the following discussion only focuses on the dependent variable (support rate).
  
  Because we found that there are regions with the same zip code in the data, their latitude and longitude are the same, and their area is the same. So in the final result, these locations will be displayed in the same area. In order to reduce unnecessary troubles and the running speed of the data, we decided to clean up and operate the data of the same geographic location and zip code.
  
The theory of our method is:
  Areas in the same postcode have the same geographic location, but there are different voting locations. So we will calculate the total number of voters in each polling station and add them together as the total number of voters in the same postcode area. Then we create a new column of data as the area with the same geographic location and postcode. The number of people supported by this party accounts for the total number of people in the area. The percentage of voters. Compared with before using this method, this operation reduces the drawing time and improves work efficiency. And keep the data results and generated maps consistent with expectations.
  

```{r read shp file and merge with existing data}
library(sf)

au.shape.1 <- st_read("Data/Australia/Au shapefiles/POA_2016_AUST.shp")

# Data for Coalition
Coalition.independent.table <- booth.results.2019 %>%
  filter(party == "Coalition") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Median_tot_prsnl_inc_weekly)

## Remove repeated data
Coalition.independent.table <- dplyr::distinct(Coalition.independent.table)

## Merge data by postcode
Coalition.independent.table <- merge(au.shape.1,
  Coalition.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Greens
Greens.independent.table <- booth.results.2019 %>%
  filter(party == "Greens") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Median_tot_prsnl_inc_weekly)

## Remove repeated data
Greens.independent.table <- dplyr::distinct(Greens.independent.table)

## Merge data by postcode
Greens.independent.table <- merge(au.shape.1,
  Greens.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for One Nation
OneNation.independent.table <- booth.results.2019 %>%
  filter(party == "One Nation") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Median_tot_prsnl_inc_weekly)

## Remove repeated data
OneNation.independent.table <- dplyr::distinct(OneNation.independent.table)

## Merge data by postcode
OneNation.independent.table <- merge(au.shape.1,
  OneNation.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Labor
Labor.independent.table <- booth.results.2019 %>%
  filter(party == "Labor") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Median_tot_prsnl_inc_weekly)

## Remove repeated data
Labor.independent.table <- dplyr::distinct(Labor.independent.table)

## Merge data by postcode
Labor.independent.table <- merge(au.shape.1,
  Labor.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################

# Data for Other
Other.independent.table <- booth.results.2019 %>%
  filter(party == "Other") %>%
  dplyr::select(POA_CODE16, party, Median_age_persons, Median_rent_weekly, Median_tot_prsnl_inc_weekly)

## Remove repeated data
Other.independent.table <- dplyr::distinct(Other.independent.table)

## Merge data by postcode
Other.independent.table <- merge(au.shape.1,
  Other.independent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)

####################


```
```{r clean and merge for denpendent varaible prop}

#coalition dependent variable table 
Coalition.dependent.table<-booth.results.2019 %>%
  filter(party == "Coalition" )%>%
  mutate(sumOfVotes.per.pollingPlace = n/prop)%>%
  dplyr::select(POA_CODE16, party, n,  sumOfVotes.per.pollingPlace)%>%
   group_by(POA_CODE16)%>%
  summarise(totalVotes.Coalition = sum(n, na.rm = TRUE), totalVotes = sum(sumOfVotes.per.pollingPlace, na.rm = TRUE))%>%
  mutate(prop.within.samePostCode = (totalVotes.Coalition/totalVotes))

Coalition.dependent.table$prop.within.samePostCode[is.na(Coalition.dependent.table$prop.within.samePostCode)] <- 0

Coalition.dependent.table <-merge(au.shape.1,
  Coalition.dependent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)


#dependent table for the party-Greens 
Greens.dependent.table <- booth.results.2019 %>%
  filter(party == "Greens" )%>%
  mutate(sumOfVotes.per.pollingPlace = n/prop)%>%
  dplyr::select(POA_CODE16, party, n,  sumOfVotes.per.pollingPlace)%>%
   group_by(POA_CODE16)%>%
  summarise(totalVotes.Greens = sum(n, na.rm = TRUE), totalVotes = sum(sumOfVotes.per.pollingPlace, na.rm = TRUE))%>%
  mutate(prop.within.samePostCode = (totalVotes.Greens/totalVotes))

Greens.dependent.table$prop.within.samePostCode[is.na(Greens.dependent.table$prop.within.samePostCode)] <- 0

Greens.dependent.table <-merge(au.shape.1,
  Greens.dependent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)


#dependent table for the party-Labor
Labor.dependent.table <- booth.results.2019 %>%
  filter(party == "Labor" )%>%
  mutate(sumOfVotes.per.pollingPlace = n/prop)%>%
  dplyr::select(POA_CODE16, party, n,  sumOfVotes.per.pollingPlace)%>%
   group_by(POA_CODE16)%>%
  summarise(totalVotes.Labor = sum(n, na.rm = TRUE), totalVotes = sum(sumOfVotes.per.pollingPlace, na.rm = TRUE))%>%
  mutate(prop.within.samePostCode = (totalVotes.Labor/totalVotes))

Labor.dependent.table$prop.within.samePostCode[is.na(Labor.dependent.table$prop.within.samePostCode)] <- 0

Labor.dependent.table <-merge(au.shape.1,
  Labor.dependent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)


#dependent table for the party-OneNation
OneNation.dependent.table <- booth.results.2019 %>%
  filter(party == "One Nation" )%>%
  mutate(sumOfVotes.per.pollingPlace = n/prop)%>%
  dplyr::select(POA_CODE16, party, n,  sumOfVotes.per.pollingPlace)%>%
   group_by(POA_CODE16)%>%
  summarise(totalVotes.OneNation = sum(n, na.rm = TRUE), totalVotes = sum(sumOfVotes.per.pollingPlace, na.rm = TRUE))%>%
  mutate(prop.within.samePostCode = (totalVotes.OneNation/totalVotes))

OneNation.dependent.table$prop.within.samePostCode[is.na(OneNation.dependent.table$prop.within.samePostCode)] <- 0

OneNation.dependent.table <-merge(au.shape.1,
  OneNation.dependent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)


#dependent table for the party-Other
Other.dependent.table <- booth.results.2019 %>%
  filter(party == "Other" )%>%
  mutate(sumOfVotes.per.pollingPlace = n/prop)%>%
  dplyr::select(POA_CODE16, party, n,  sumOfVotes.per.pollingPlace)%>%
   group_by(POA_CODE16)%>%
  summarise(totalVotes.Other = sum(n, na.rm = TRUE), totalVotes = sum(sumOfVotes.per.pollingPlace, na.rm = TRUE))%>%
  mutate(prop.within.samePostCode = (totalVotes.Other/totalVotes))

Other.dependent.table$prop.within.samePostCode[is.na(Other.dependent.table$prop.within.samePostCode)] <- 0

Other.dependent.table <-merge(au.shape.1,
  Other.dependent.table,
  by="POA_CODE16", duplicateGeoms = TRUE)


```

## Map Plotting
  In this part we spent 8 maps, 4 maps about the independent variable age classification according to each political party, the distribution in Australia. Other four maps show the distribution of the support rate (dependent variable) of each political party in Australia. We will discuss and write down findings based on these figures.

```{r Coalition/Age}

library(mapdeck)

key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'

mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Coalition.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)

```

```{r Greens/Age}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Greens.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```

```{r One Nation/Age}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = OneNation.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```

```{r labor/Age}
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Labor.independent.table, 
   layer = "polygon_layer", 
   fill_colour = "Median_age_persons", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE)
```


## Map dependent variable for the party Coalition
```{r Coalition/prop}

Coalition.dependent.table <- Coalition.dependent.table %>%
mutate(prop.within.samePostCode2 = cut(prop.within.samePostCode, breaks=c(quantile(prop.within.samePostCode,
probs = seq(0, 1, by = 0.20))),
labels=c("0-20","20-40","40-60","60-80","80-100"), include.lowest=TRUE))


key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'

library(mapdeck)

mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Coalition.dependent.table, 
   layer = "polygon_layer", 
   fill_colour = "prop.within.samePostCode2", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE,
  legend_options = list(title = "Vote Proportion For Coalition"))  

```
#Map dependent variable for the party Greens
```{r}
#set label
Greens.dependent.table <- Greens.dependent.table %>%
mutate(prop.within.samePostCode2 = cut(prop.within.samePostCode, breaks=c(quantile(prop.within.samePostCode,
probs = seq(0, 1, by = 0.20))),
labels=c("0-20","20-40","40-60","60-80","80-100"), include.lowest=TRUE))
key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Greens.dependent.table, 
   layer = "polygon_layer", 
   fill_colour = "prop.within.samePostCode2", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE,
  legend_options = list(title = "Vote Proportion For Greens"))  
```

#Map dependent variable for the party-Labor
```{r}
#set label
Labor.dependent.table <- Labor.dependent.table %>%
mutate(prop.within.samePostCode2 = cut(prop.within.samePostCode, breaks=c(quantile(prop.within.samePostCode,
probs = seq(0, 1, by = 0.20))),
labels=c("0-20","20-40","40-60","60-80","80-100"), include.lowest=TRUE))
key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = Labor.dependent.table, 
   layer = "polygon_layer", 
   fill_colour = "prop.within.samePostCode2", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE,
  legend_options = list(title = "Vote Proportion For Labor"))  
```

#Map dependent variable for the party-OneNation
```{r}
#set label
OneNation.dependent.table <- OneNation.dependent.table %>%
mutate(prop.within.samePostCode2 = cut(prop.within.samePostCode, breaks=c(quantile(prop.within.samePostCode,
probs = seq(0, 1, by = 0.20))),
labels=c("0-20","20-40","40-60","60-80","80-100"), include.lowest=TRUE))
key <- 'pk.eyJ1IjoiZmFuc29uZzk5NiIsImEiOiJja2tvemQ1aWcxa3o3MnBvY3JjeXdmaW1yIn0.1TaYyPHIjaCvbeL6bfJFug'
mapdeck(token = key, style = mapdeck_style("light")) %>%
  add_polygon(
    data = OneNation.dependent.table, 
   layer = "polygon_layer", 
   fill_colour = "prop.within.samePostCode2", 
   palette = "diverge_hsv", 
   fill_opacity = .9, 
  legend = TRUE,
  legend_options = list(title = "Vote Proportion For OneNation"))  
```





### Key findings
  
