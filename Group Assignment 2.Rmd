---
title: "Group Assignment 2"
author: 'Group 2'
date: "2021/2/3"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, messages = FALSE)

library (tidyverse)

```


## Data Preparetion


### Downloading and analysing spatial data for elections

\vspace{6mm}

```{r function to download booth data, eval=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/
                  HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), 
           skip = 1)
  
}

```

```{r function to download booth data2, include=FALSE}


dl.booth.data <- function(x){
  
  read.csv(paste0('https://results.aec.gov.au/24310/Website/Downloads/HouseStateFirstPrefsByPollingPlaceDownload-24310-', x, '.csv'), skip = 1)
  
}

```
\vspace{6mm}

Write out code that downloads and binds the polling place results for each state: 

\vspace{6mm}

```{r load and code 2019 booth data}

booth.results.2019 <- bind_rows(dl.booth.data('NSW'),
                                dl.booth.data('VIC'),
                                dl.booth.data('QLD'),
                                dl.booth.data('WA'),
                                dl.booth.data('SA'),
                                dl.booth.data('TAS'),
                                dl.booth.data('ACT'),
                                dl.booth.data('NT'))


```

\vspace{6mm}

In its raw form this needs some work, though. For instance, there are a lot of small parties who only contested a handful of seats in the election. You can see this for yourself with the syntax: 

\vspace{6mm}

```{r check party coding, eval=FALSE}

table(booth.results.2019$PartyNm)

```

\vspace{6mm}

Therefore we recode the variable `PartyNm`, saving this as `party`: 

\vspace{6mm}

```{r recode party}

booth.results.2019 <- booth.results.2019 %>% 
  mutate(party = dplyr::recode(PartyNm,
                               "Liberal" = 'Coalition',
                               "The Greens" = 'Greens',
                               "Labor" = 'Labor',
                               "Informal" = 'Informal',
                               "Pauline Hanson's One Nation" = 'One Nation',
                               "The Nationals"  = 'Coalition',
                               "The Greens (VIC)" = 'Greens',                    
                               "Australian Labor Party"  = 'Labor',
                               "Liberal National Party of Queensland" = 'Coalition',
                               "The Greens (WA)" = 'Greens',
                               "National Party" = 'Coalition',
                               "Australian Labor Party (Northern Territory) Branch"  = 
                                 'Labor',
                               "Country Liberals (NT)" = 'Coalition',
         .default = 'Other')) %>%
  filter(party != 'Informal')
  
```

\vspace{6mm}

Roll up party votes at each polling place and clean up some of the polls with missing data using `mutate_at`

\vspace{6mm}

```{r calculate proportions for each polling place, message=FALSE, warning=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
group_by(PollingPlaceID, party) %>%
  dplyr::summarise(n = sum(OrdinaryVotes)) %>%
  spread(party, n) %>%
  mutate_at(vars(-PollingPlaceID), 
                   .funs = list(missing = ~ ifelse(is.na(.), 'Yes', 'No'))) %>% 
  mutate_at(vars(-PollingPlaceID), ~ifelse(is.na(.), 0, .))


```

\vspace{6mm}

`gather` to organise the data: 

\vspace{6mm}

```{r other stuff}

  
booth.results.2019 <- booth.results.2019 %>% 
    gather(party, n, 
           Coalition, Greens, Labor, `One Nation`, Other) %>% 
    dplyr::select(PollingPlaceID, party, n) %>% 
    merge(booth.results.2019 %>% 
            gather(party, missing, 
                   Coalition_missing, Greens_missing, 
                   Labor_missing, `One Nation_missing`,
                   Other_missing) %>%
            mutate(party = gsub('_missing', '', party)) %>% 
            dplyr::select(PollingPlaceID, party, missing)) %>% 
  group_by(PollingPlaceID) %>%
  mutate(prop = n / sum(n))

```

\vspace{6mm}

Calculated the proportion of votes at each polling place received by each party saved as `prop`. 

Merging booth information from the AEC on to data frame, and then removing rows with missing data. 

\vspace{6mm}

```{r booth information, eval=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```

```{r booth information2, include=FALSE}
  
booth.results.2019 <- booth.results.2019 %>% 
  merge(read.csv('https://results.aec.gov.au/24310/Website/Downloads/GeneralPollingPlacesDownload-24310.csv', skip = 1) %>%
            dplyr::rename(state = State, 
                          division = DivisionNm,
                          PollingPlace = PollingPlaceNm,
                          POA_CODE16 = PremisesPostCode) %>% 
  dplyr::select(state, division, PollingPlaceID, PollingPlace,
                POA_CODE16, Latitude, Longitude)) %>% 
  filter(!is.na(Latitude)) %>% 
  filter(!PollingPlace %in% grep('PREPOLL',
                                 PollingPlace, 
                                 value = T)) 
  

```


\vspace{6mm}


### Building on data

\vspace{6mm}


```{r read and merge datapacks, eval=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))


```


```{r read and merge datapacks2, include=FALSE}

booth.results.2019 <- booth.results.2019 %>% 
  left_join(read.csv('Data/Australia/abs data/2016Census_G02_AUS_POA.csv') %>% 
  mutate(POA_CODE16 = as.numeric(gsub('POA', '', POA_CODE_2016))) %>% 
  dplyr::select(-POA_CODE_2016))


```

\vspace{6mm}

Your final data frame should look like this:


```{r check data}

booth.results.2019

tail(booth.results.2019)

variable <- c('Median_age_persons','Median_rent_weekly','Median_tot_prsnl_inc_weekly')
head(booth.results.2019[variable])
summary(booth.results.2019[variable], na.rm=TRUE)

mean(booth.results.2019$Median_age_persons, na.rm=TRUE)

library(psych)

describe(booth.results.2019[variable])




```
```{r fit the first linear model to county, warning=FALSE, message=FALSE, cache=FALSE}
library(tidyverse)
booth.results.2019.Coalition <- booth.results.2019 %>% filter(party == "Coalition")
booth.results.2019.Greens <- booth.results.2019 %>% filter(party == "Greens")
booth.results.2019.Labor <- booth.results.2019 %>% filter(party == "Labor")
booth.results.2019.OneNation <- booth.results.2019 %>% filter(party == "One Nation")
booth.results.2019.Other <- booth.results.2019 %>% filter(party == "Other")

library(arm)
booth.model.coliation <- glm(prop ~ Median_age_persons + Average_num_psns_per_bedroom 
                     + Median_tot_prsnl_inc_weekly,
                     family=poisson(link = log),
                     data=booth.results.2019.Coalition)

booth.model.greens <- glm(prop ~ Median_age_persons + Average_num_psns_per_bedroom 
                     + Median_tot_prsnl_inc_weekly,
                     family=binomial(link = log),
                     data=booth.results.2019.Greens)

booth.model.labor <- glm(prop ~ Median_age_persons + Average_household_size 
                     + Median_tot_prsnl_inc_weekly,
                     family=binomial(link = log),
                     data=booth.results.2019.Labor)

booth.model.onenation <- glm(prop ~ Median_age_persons + Median_rent_weekly 
                     + Median_tot_prsnl_inc_weekly,
                     family=binomial(link = log),
                     data=booth.results.2019.OneNation)

booth.model.other <- glm(prop ~ Median_age_persons + Median_rent_weekly 
                     + Average_household_size,
                     family=poisson(link = log),
                     data=booth.results.2019.Other)

display(booth.model.coliation)
display(booth.model.greens)
display(booth.model.labor)
display(booth.model.onenation)
display(booth.model.other)


```


```{r}
library(sf)

au.shape.1 <- st_read("Data/Australia/Au shapefiles/POA_2016_AUST.shp")

head(au.shape.1)

au.shape.2 <- merge(au.shape.1,
  booth.results.2019 %>%
    dplyr::select(PollingPlaceID, party, n, missing, prop, state, division, PollingPlaceID, POA_CODE16, Latitude, Longitude, Median_age_persons, Median_tot_prsnl_inc_weekly, Median_rent_weekly, Average_household_size),
  by="POA_CODE16", duplicateGeoms = TRUE)

head(au.shape.2)
```
```{r}
library(mapdeck)

booth.results.2019.Coalition <- au.shape.2 %>%
  filter(party == "Coalition")

key <- 'pk.eyJ1Ijoia2Vub2tpIiwiYSI6ImNra296Ymp4NDAyY2wzMW1vbzQwazJkazAifQ.H130BX9RduEUtpGndRxefw'

mapdeck(token = key, style = mapdeck_style("light")) %>%
 add_polygon(
    data = booth.results.2019.Coalition, 
   layer = "polygon_layer", 
    fill_colour = "Average_household_size", 
  palette = "diverge_hsv", 
   fill_opacity = .9, 
   legend = TRUE)
```



### Examining these data 

Once you have loaded and cleaned your data, you will then use these to examine some relationships between the demographics of the communities around polling places and party vote share at each booth. 
Examine how different spatial patterns interact with with electoral outcomes. Do this using the tools we covered in this morning's lab.

For this you will undertake three main steps:

1. Select what you believe to be appropriate predictors for election results (the variable `prop`, which should be subset by `party`). You should have at least three predictors.

2. Examine your predictors in $R$. Look at their mean, standard deviation, distribution, etc. Do they need to be recoded in any way? Write up your data cleaning decisions in the Markdown file, and include and descriptive analysis you do. 

3. Conduct some descriptive analyses of these data.

Each step in your Markdown file should be clearly labelled. 


### Part 2: Regression and interactive maps

The second half of the afternoon lab will be spent conducting further analysis using these data. For this section of the project, you will  also undertake three main steps:

1. Fit regressions to your data. For this you should at least three independent variables from the items you examined this morning. This should be done seperately for each of the party categories in the cleaned AEC electoral data. 

2.	Create an interactive map between at least one of the dependent variables and one independent variable.

3. Write up your key findings.
